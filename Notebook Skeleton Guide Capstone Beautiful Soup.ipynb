{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Webscrapping using BeautifulSoup\n",
    "\n",
    "This notebook contains guidances & tasks on the data processing for the application\n",
    "\n",
    "Prepared by : Ricky Ariansyah\n",
    "\n",
    "Batch : Vulcan DA Online\n",
    "\n",
    "## Background / Latar Belakang\n",
    "\n",
    "Web Scrapping dan analisa data pekerjaan di indonesia pada website kalibrr \n",
    "\n",
    "`https://www.kalibrr.id/job-board/te/data/1`\n",
    "\n",
    "Goals :\n",
    "\n",
    "1. Dari Halaman tersebut carilah title pekerjaan , lokasi pekerjaan , tanggal pekerjaan di post dan dealine submit permohonan, dan perusahaan\n",
    "2. tariklah 15 halaman\n",
    "3. Buatlah plot dari jumlah pekerjaan berdasarkan lokasi.\n",
    "\n",
    "\n",
    "Rubrics : \n",
    "\n",
    "[2 points] Environment preparation []\n",
    "\n",
    "[5 points] Finding the right key to scrap the data & Extracting the right information []\n",
    "\n",
    "[5 points] Creating data frame & Data wrangling []\n",
    "\n",
    "[2 points] Creating a tidy python notebook as a report []\n",
    " \n",
    "[2 points] Implement it on Flask dashboard []\n",
    "\n",
    "\n",
    "### Detil\n",
    "\n",
    "1. Struktur URL - `https://www.kalibrr.id/job-board/te/data/1` \n",
    "\n",
    "`https://www.kalibrr.id/` -> adalah base_url / url utama\n",
    "`/te/data/1` -> adalah endpoint, angka 1 pada endpoint tersebut adalah represntasi halaman yang sedang diakses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "- beautifulSoup4\n",
    "- pandas\n",
    "- flask\n",
    "- matplotlib\n",
    "\n",
    "Atau Bapak Ibu cukup menginstall requirements.txt dengan cara berikut\n",
    "\n",
    "```python\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create / Reproducible environment\n",
    "\n",
    "\n",
    "1. Aktifkan environment\n",
    "```\n",
    "conda create --name \"vulcan_capstone\"\n",
    "```\n",
    "\n",
    "2. Install depedencies\n",
    "```\n",
    "pip install  nama_dependy==versi\n",
    "```  \n",
    "\n",
    "3. Export environment: membuat daftar packages beserta versinya.\n",
    "```\n",
    "pip list --format=freeze > requirements.txt\n",
    "```\n",
    "\n",
    "## Import Enviroment\n",
    "\n",
    "1. Aktifkan environment yang ingin digunakan\n",
    "    ```\n",
    "    conda activate <ENV_NAME>\n",
    "    ```\n",
    "\n",
    "2. Navigasikan path ke folder di mana file `requirements.txt` / atau sesuai dengan nama export enviroment diatas berada\n",
    "    ```\n",
    "    cd <PATH_TO_REQUIREMENTS>\n",
    "    ```\n",
    "\n",
    "3. Instalasi packages dari file tersebut\n",
    "    ```\n",
    "    pip install -r requirements.txt / nama file txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting the Data and Creating a BeautifulSoup\n",
    "\n",
    "Let's begin with requesting the web from the site with `get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.275508Z",
     "start_time": "2020-01-13T05:12:20.009898Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TZ'] = 'Asia/Jakarta'\n",
    "url_get = requests.get('https://www.kalibrr.id/job-board/te/data/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what exactly you get from the `request.get`, we can use .content so ee what we exactly get, in here i slice it so it won't make our screen full of the html we get from the page. You can delete the slicing if you want to see what we fully get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.290648Z",
     "start_time": "2020-01-13T05:12:23.277650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'!DOCTYPE html><html lang=\"en\"><head><meta name=\"viewport\" content=\"width=device-width\"/><meta charSet=\"utf-8\"/><script type=\"application/ld+json\">{\\n    \"@context\": \"https://schema.org\",\\n    \"@type\": \"WebSite\",\\n    \"url\": \"https://www.kalibrr.com\",\\n    \"potentialAction\": [\\n      {\\n        \"@type\": \"SearchAction\",\\n        \"target\": \"https://www.kalibrr.com/job-board/te/={search_term_string}\",\\n        \"query-input\": \"required name=search_term_string\"\\n      }\\n     ]\\n  }</script><meta property=\"og:i'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_get.content[1:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we get a very unstructured and complex html, which actually contains the codes needed to show the webpages on your web browser. But we as human still confused what and where we can use that piece of code, so here where we use the beautifulsoup. Beautiful soup class will result a beautifulsoup object. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. \n",
    "\n",
    "Let's make Beautiful soup object and feel free to explore the object here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.808122Z",
     "start_time": "2020-01-13T05:12:23.292610Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "soup = BeautifulSoup(url_get.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right key to scrap the data & Extracting the right information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah langkah langkah untuk mengestrak data data pada web kalibrr\n",
    "\n",
    "**1. Mencari Page Terakhir atau Total Page**\n",
    "\n",
    "pada halaman list pekerjaan di kalibrr dapat kita lihat pagination, total page / total halaman dapat kita ambil sebelum tanda panah yang paling kanan (tombol next page), kemudian kita ambil content sebelumnya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "Total Page : 60\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('ul', {\"class\" : \"k-flex k-justify-center k-items-center k-my-8\"}).find_all('li')[-2].get_text())\n",
    "\n",
    "total_page = int(soup.find('ul', {\"class\" : \"k-flex k-justify-center k-items-center k-my-8\"}).find_all('li')[-2].get_text())\n",
    "\n",
    "print(f\"Total Page : {total_page}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Ekstrasi data Pekerjaan dari list card**\n",
    "\n",
    "pada halaman list pekerjaan di kalibrr dapat kita lihat list card tampilan pekerjaan, pada card ini terdapat data yang perlu kita ekstrak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kita akan ambil semua tag div yang mempunyai atribut :\n",
    "\n",
    "1. itemscope: true\n",
    "2. itemtype: \"http://schema.org/ListItem\"\n",
    "3. itemprop: \"itemListElement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_job = soup.find_all('div', {'itemscope': True, 'itemtype' : 'http://schema.org/ListItem','itemprop' : \"itemListElement\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasilnya akan berbentuk larik / array html yang dapat kita looping\n",
    "\n",
    "kita lihat hasil index 0 untuk tag yang kita find_all diatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"k-grid k-border-tertiary-ghost-color k-text-sm k-p-4 md:k-p-6 css-1b4vug6\" itemprop=\"itemListElement\" itemscope=\"\" itemtype=\"http://schema.org/ListItem\">\n",
      " <a class=\"k-bg-white k-flex k-items-center k-flex-shrink k-justify-center k-text-4xl k-text-subdued k-overflow-hidden k-px-4 k-py-2 k-row-span-4\" href=\"/c/pgi-data/jobs\">\n",
      "  <div>\n",
      "   <img alt=\"PGI Data\" class=\"k-block k-max-w-full k-max-h-full k-bg-white k-mx-auto\" decoding=\"async\" height=\"80\" loading=\"eager\" src=\"https://rec-data.kalibrr.com/www.kalibrr.com/logos/Z7AL3F4XGKPLCEW9TFDFDZK33247MQ8J9PSHES26-6080167e.png\" width=\"130\"/>\n",
      "  </div>\n",
      " </a>\n",
      " <div class=\"k-col-start-3 k-row-start-1\">\n",
      "  <h2 class=\"k-text-xl k-font-medium\">\n",
      "   <a class=\"k-text-primary-color\" href=\"/c/pgi-data/jobs/174503/net-developer\" itemprop=\"name\">\n",
      "    .Net Developer\n",
      "   </a>\n",
      "  </h2>\n",
      " </div>\n",
      " <style data-emotion=\"css 1gzvnis\">\n",
      "  .css-1gzvnis{display:-webkit-box!important;-webkit-line-clamp:2;-webkit-box-orient:vertical;}\n",
      " </style>\n",
      " <div class=\"k-text-xs k-text-subdued k-col-start-1 k-row-start-5 k-col-span-3 k-mt-7 k-h-8 k-text-ellipsis k-overflow-hidden k-whitespace-normal css-1gzvnis\">\n",
      "  <div class=\"\">\n",
      "  </div>\n",
      " </div>\n",
      " <div class=\"k-col-start-3 k-row-start-3 k-flex k-flex-col k-justify-end\">\n",
      "  <span class=\"k-inline-flex k-items-center k-mb-1\">\n",
      "   <a class=\"k-text-subdued\" href=\"/c/pgi-data/jobs\">\n",
      "    PGI Data\n",
      "   </a>\n",
      "   <span class=\"k-ml-1 k-mb-0.5\">\n",
      "    <div class=\"\" style=\"display:inline\" title=\"verified-business\">\n",
      "     <svg aria-hidden=\"true\" class=\"MuiSvgIcon-root k-text-primary-color-500 MuiSvgIcon-fontSizeSmall\" focusable=\"false\" height=\"20\" viewbox=\"0 0 24 24\" width=\"20\">\n",
      "      <path d=\"M12 1L3 5v6c0 5.55 3.84 10.74 9 12 5.16-1.26 9-6.45 9-12V5l-9-4zm-2 16l-4-4 1.41-1.41L10 14.17l6.59-6.59L18 9l-8 8z\">\n",
      "      </path>\n",
      "     </svg>\n",
      "    </div>\n",
      "   </span>\n",
      "  </span>\n",
      "  <div class=\"k-flex k-flex-col md:k-flex-row\">\n",
      "   <a class=\"k-text-subdued k-block\" href=\"/job-board/l/Jakarta\">\n",
      "    Jakarta, Indonesia\n",
      "   </a>\n",
      "  </div>\n",
      " </div>\n",
      " <div class=\"k-col-start-5 k-row-start-1 k-text-right k-text-xs k-text-subdued k-hidden k-mb-2 md:k-block\">\n",
      "  <span class=\"k-block k-mb-1\">\n",
      "   Posted 7 days ago • Apply before 19 May\n",
      "  </span>\n",
      "  <span class=\"k-block\">\n",
      "   Recruiter was hiring 2 hours ago\n",
      "  </span>\n",
      " </div>\n",
      " <div class=\"k-col-start-5 k-row-start-1 md:k-flex md:k-justify-end md:k-items-end md:k-row-start-3\">\n",
      "  <div class=\"k-grid k-grid-rows-3\">\n",
      "   <button class=\"k-btn-tertiary k-inline-flex k-items-center k-justify-center k-row-start-1 k-row-span-2 md:k-row-start-2\">\n",
      "    <svg aria-hidden=\"true\" class=\"MuiSvgIcon-root md:k-mr-2\" focusable=\"false\" viewbox=\"0 0 24 24\">\n",
      "     <path d=\"M16.5 3c-1.74 0-3.41.81-4.5 2.09C10.91 3.81 9.24 3 7.5 3 4.42 3 2 5.42 2 8.5c0 3.78 3.4 6.86 8.55 11.54L12 21.35l1.45-1.32C18.6 15.36 22 12.28 22 8.5 22 5.42 19.58 3 16.5 3zm-4.4 15.55l-.1.1-.1-.1C7.14 14.24 4 11.39 4 8.5 4 6.5 5.5 5 7.5 5c1.54 0 3.04.99 3.57 2.36h1.87C13.46 5.99 14.96 5 16.5 5c2 0 3.5 1.5 3.5 3.5 0 2.89-3.14 5.74-7.9 10.05z\">\n",
      "     </path>\n",
      "    </svg>\n",
      "    <span class=\"k-hidden md:k-flex md:k-justify-end\">\n",
      "     Save\n",
      "    </span>\n",
      "   </button>\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list_job[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library tambahan datetime untuk mengekstraksi data tanggal dikarenakan pada web berbentuk string, dan ini perlu kita convert ke dalam format datetime string agar dapat dengan mudah kita proses saat sudah menjadi data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "membuat fungsi untuk ekstraksi string ke datetime string\n",
    "\n",
    "contoh masukkan : \"a day ago\"\n",
    "\n",
    "contoh keluaran : \"2023 05 13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_date(str_days_ago):\n",
    "    TODAY = datetime.today()\n",
    "    splitted = str_days_ago.split()\n",
    "    if len(splitted) == 1 and splitted[0].lower() == 'today':\n",
    "        return str(TODAY.isoformat())\n",
    "    elif len(splitted) == 1 and splitted[0].lower() == 'yesterday':\n",
    "        date = TODAY - relativedelta(days=1)\n",
    "        return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['minute', 'minutes', 'mins', 'min', 'm']:\n",
    "        return str(TODAY.isoformat())\n",
    "    elif splitted[1].lower() in ['hour', 'hours', 'hr', 'hrs', 'h']:\n",
    "       return str(TODAY.isoformat())\n",
    "    elif splitted[1].lower() in ['day', 'days', 'd']:\n",
    "        if splitted[0].isdigit():\n",
    "            date = TODAY - relativedelta(days=int(splitted[0]))\n",
    "            return str(date.isoformat())\n",
    "        else:\n",
    "            date = TODAY - relativedelta(days=int(1))\n",
    "            return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['wk', 'wks', 'week', 'weeks', 'w']:\n",
    "        if splitted[0].isdigit():\n",
    "            date = TODAY - relativedelta(weeks=int(splitted[0]))\n",
    "            return str(date.isoformat())\n",
    "        else:\n",
    "            date = TODAY - relativedelta(weeks=int(1))\n",
    "            return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['mon', 'mons', 'month', 'months', 'm']:\n",
    "        if splitted[0].isdigit():\n",
    "         date = TODAY - relativedelta(months=int(splitted[0]))\n",
    "         return str(date.isoformat())\n",
    "        else:\n",
    "         date = TODAY - relativedelta(months=int(1))\n",
    "         return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['yrs', 'yr', 'years', 'year', 'y']:\n",
    "        if splitted[0].isdigit():\n",
    "            date = TODAY - relativedelta(years=int(splitted[0]))\n",
    "            return str(date.isoformat())\n",
    "        else:\n",
    "            date = TODAY - relativedelta(years=int(1))\n",
    "            return str(date.isoformat())\n",
    "    else:\n",
    "        return \"Wrong Argument format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get tahun sekarang karena kita berpatokan pada tahun berjalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ekstraksi data list pekerjaan, kita akan loop variabel `list_job`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping untuk ganti bahasa kota dari inggris ke indonesia secara statis\n",
    "mapping = {\n",
    "    'South Jakarta': 'Jakarta Selatan', \n",
    "    'West Jakarta': 'Jakarta Barat', \n",
    "    'North Jakarta': 'Jakarta Utara', \n",
    "    'East Jakarta':'Jakarta Timur', \n",
    "    'Jakarta':'Jakarta Pusat', \n",
    "    'South Tangerang': 'Tangerang Selatan', \n",
    "    'Bandung Kota':'Bandung', \n",
    "    'Bandung Kabupaten':'Bandung', \n",
    "    'Bogor Kota':'Bogor', \n",
    "    'Central Jakarta': 'Jakarta Pusat', \n",
    "    'Central Jakarta City': \n",
    "    'Jakarta Pusat', \n",
    "    'Central Lampung': \n",
    "    'Lampung', \n",
    "    'Kota Jakarta Barat': 'Jakarta Barat', \n",
    "    'Kota Jakarta Pusat':'Jakarta Pusat', \n",
    "    'Kota Jakarta Selatan':'Jakarta Selatan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_job:\n",
    "    # nama pekerjaan terdapat pada tag h2 > a\n",
    "            job_title = item.select_one('h2 a').get_text().strip()\n",
    "            # tanggal post kita tag turunan beserta class nya kemudian kita ekstrak test dan split ambil index 0 dan replace Posted, kemudian convert\n",
    "            post_date = datetime.strptime(\n",
    "                get_past_date(\n",
    "                item.select_one(\"div.k-col-start-5 span:first-of-type\").text.strip().split(\"•\")[0].strip().replace(\"Posted\", \"\")\n",
    "                ), \n",
    "                \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "                ).strftime('%Y-%m-%d %H:%M:%S').split()[0] + \"\"\n",
    "            # deadline kita tag turunan beserta class nya kemudian kita ekstrak test dan split ambil index 1 dan replace Apply before kemudian + tahun sekarang, kemduain ganti format agar sama dengan tanggal post diatas\n",
    "            date_posting = item.select_one(\"div.k-col-start-5 span:first-of-type\").text.strip().split(\"•\")[1].strip().replace(\"Apply before\", \"\").strip() + \" \" + str(datetime.now().year)\n",
    "            deadline_date = datetime.strptime(date_posting, '%d %b %Y') + timedelta(days=1)\n",
    "            deadline_date = deadline_date.strftime('%Y-%m-%d %H:%M:%S').split()[0] + \"\"\n",
    "            # lokasi kota kita ambil tag turunan beserta class nya lalu ambil text kemudian ambil index [0], kita replace bahasa kota yang belum sesuai dengan mapping\n",
    "            nama_kota = item.select_one(\"div.k-col-start-3 div.k-flex > a\").text.strip().split(\",\")[0]\n",
    "            nama_kota_new = nama_kota.replace(nama_kota, mapping.get(nama_kota, nama_kota))\n",
    "            # lokasi negara kita ambil tag turunan beserta class nya lalu ambil text kemudian ambil index [1]\n",
    "            country = item.select_one(\"div.k-col-start-3 div.k-flex > a\").text.strip().split(\",\")[1].strip()\n",
    "          \n",
    "\n",
    "          \n",
    "            # print(f\"Nama Pekerjaan : {job_title}\")\n",
    "            # print(f'Tanggal Post : {post_date}') \n",
    "            # print(f\"Tanggal Deadline : {deadline_date}\")\n",
    "            # print(f'Lokasi Kota : {nama_kota_new}')\n",
    "            # print(f'Lokasi Negara : {country}')\n",
    "            # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat function scarapping halaman\n",
    "def func_scrape(page = 1):\n",
    "    # Inisiasi awal\n",
    "    base_url = 'https://www.kalibrr.id/job-board/te/data/'\n",
    "    url_get = requests.get(base_url + str(1))\n",
    "    soup = BeautifulSoup(url_get.content,\"html.parser\")\n",
    "\n",
    "    #  Total Page \n",
    "    total_page = int(soup.find('ul', {\"class\" : \"k-flex k-justify-center k-items-center k-my-8\"}).find_all('li')[-2].get_text())\n",
    "    print(f\"Total Page : {total_page}\")\n",
    "\n",
    "    # inisiasi list kosong\n",
    "    temp = [] #initiating a list\n",
    "   \n",
    "    print(f\"Start Scrapping {base_url}\")\n",
    "\n",
    "    page_scrap = page if page > 1 else total_page\n",
    "    for i in range(1, page_scrap + 1):\n",
    "        progress = round((i / page_scrap) * 100) # untuk menampilkan presentasi progress pada terminal\n",
    "        \n",
    "        print(f\"{progress}% | page {i} dari {page_scrap} Pages\")\n",
    "\n",
    "        url = 'https://www.kalibrr.id/job-board/te/data/' + str(i)\n",
    "        url_get = requests.get(url)\n",
    "        soup = BeautifulSoup(url_get.content,\"html.parser\")\n",
    "    \n",
    "        list_job = soup.find_all('div', {'itemscope': True, 'itemtype' : 'http://schema.org/ListItem','itemprop' : \"itemListElement\"})\n",
    "\n",
    "        for item in list_job:\n",
    "            # nama pekerjaan terdapat pada tag h2 > a\n",
    "            job_title = item.select_one('h2 a').get_text().strip()\n",
    "            # tanggal post kita tag turunan beserta class nya kemudian kita ekstrak test dan split ambil index 0 dan replace Posted, kemudian convert\n",
    "            post_date = datetime.strptime(\n",
    "                get_past_date(\n",
    "                item.select_one(\"div.k-col-start-5 span:first-of-type\").text.strip().split(\"•\")[0].strip().replace(\"Posted\", \"\")\n",
    "                ), \n",
    "                \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "                ).strftime('%Y-%m-%d %H:%M:%S').split()[0] + \"\"\n",
    "            # deadline kita tag turunan beserta class nya kemudian kita ekstrak test dan split ambil index 1 dan replace Apply before kemudian + tahun sekarang, kemduain ganti format agar sama dengan tanggal post diatas\n",
    "            date_posting = item.select_one(\"div.k-col-start-5 span:first-of-type\").text.strip().split(\"•\")[1].strip().replace(\"Apply before\", \"\").strip() + \" \" + str(datetime.now().year)\n",
    "            deadline_date = datetime.strptime(date_posting, '%d %b %Y') + timedelta(days=1)\n",
    "            deadline_date = deadline_date.strftime('%Y-%m-%d %H:%M:%S').split()[0] + \"\"\n",
    "            # lokasi kota kita ambil tag turunan beserta class nya lalu ambil text kemudian ambil index [0], kita replace bahasa kota yang belum sesuai dengan mapping\n",
    "            nama_kota = item.select_one(\"div.k-col-start-3 div.k-flex > a\").text.strip().split(\",\")[0]\n",
    "            nama_kota_new = nama_kota.replace(nama_kota, mapping.get(nama_kota, nama_kota))\n",
    "            # lokasi negara kita ambil tag turunan beserta class nya lalu ambil text kemudian ambil index [1]\n",
    "            country = item.select_one(\"div.k-col-start-3 div.k-flex > a\").text.strip().split(\",\")[1].strip()\n",
    "          \n",
    "\n",
    "          \n",
    "            # print(f\"Nama Pekerjaan : {job_title}\")\n",
    "            # print(f'Tanggal Post : {post_date}') \n",
    "            # print(f\"Tanggal Deadline : {deadline_date}\")\n",
    "            # print(f'Lokasi Kota : {nama_kota_new}')\n",
    "            # print(f'Lokasi Negara : {country}')\n",
    "            # print(\"\\n\")\n",
    "    \n",
    "            temp.append({\n",
    "                \"job_title\" : item.select_one('h2 a').get_text().strip(),\n",
    "                \"city\" : nama_kota_new,\n",
    "                \"country\" : item.select_one(\"div.k-col-start-3 div.k-flex > a\").text.strip().split(\",\")[1].strip(),\n",
    "                \"date_post\": post_date,\n",
    "                \"date_deadline\": deadline_date\n",
    "            })\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(temp)\n",
    "    df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Page : 60\n",
      "Start Scrapping https://www.kalibrr.id/job-board/te/data/\n",
      "50% | page 1 dari 2 Pages\n",
      "100% | page 2 dari 2 Pages\n"
     ]
    }
   ],
   "source": [
    "function_scrapping(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the key and put the key into the `.find()` Put all the exploring the right key at this cell. (please change this markdown with your explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.878904Z",
     "start_time": "2020-01-13T05:12:23.854974Z"
    }
   },
   "outputs": [],
   "source": [
    "table = soup.find(...)\n",
    "print(table.prettify()[1:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding row length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... = table.find_all(...)\n",
    "row_length = len(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the scrapping process here (please change this markdown with your explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:24.008256Z",
     "start_time": "2020-01-13T05:12:23.980358Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = [] #initiating a tuple\n",
    "\n",
    "for i in range(1, row_length):\n",
    "\n",
    "    #scrapping process\n",
    "    \n",
    "temp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data frame & Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the array into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:41.517372Z",
     "start_time": "2020-01-13T05:12:29.130015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(...)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the data cleaning here (please change this markdown with your explanation of what you do for data wrangling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:59.165559Z",
     "start_time": "2020-01-13T05:12:58.910012Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualisation (please change this markdown with your explanation of what you do for data wrangling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing your webscrapping to the flask dashboard\n",
    "\n",
    "- Copy paste all of your web scrapping process to the desired position on the `app.py`\n",
    "- Changing the title of the dasboard at `index.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing This Notebook with Your Analysis and Conclusion\n",
    "\n",
    "First you can do start with making the data visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:20:56.208237Z",
     "start_time": "2020-01-13T05:20:56.076043Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(Put your analysis and conclusion here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement it at the webapps\n",
    "\n",
    "- You can create additional analysis from the data.\n",
    "- Implement it to the dashboard with at `app.py` dan `index.html`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
